{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilcob/-DL_PaperReadingMeeting/blob/master/.idea/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "CatEBF8yPXUy",
        "outputId": "685afed5-7584-4dc7-c7c6-284af7666da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e1b5471e89ed>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  img_np = np.array(images)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e1b5471e89ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhealth_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import cv2\n",
        " \n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/bee_data.csv')\n",
        "datapath = '/content/drive/MyDrive/bee_imgs'\n",
        "datadir = pathlib.Path(datapath)\n",
        "bees_data = list(datadir.glob('./*'))\n",
        "image_cnt = len(list(datadir.glob('*/*.png')))\n",
        "img_paths = []\n",
        "img_names = list(df['file'])\n",
        "images = []\n",
        "\n",
        "for img in img_names:\n",
        "    img_paths.append('/content/drive/MyDrive/bee_imgs/bee_imgs/'+img)\n",
        "\n",
        "for img in img_paths:\n",
        "    images.append(cv2.imread(img))\n",
        "\n",
        "img_np = np.array(images)\n",
        "\n",
        "health = df['health']\n",
        "\n",
        "enc = OneHotEncoder()\n",
        "health_encoded = enc.fit_transform(np.array(health).reshape(-1,1))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(img_np, health_encoded, test_size = 0.2, shuffle=True)\n",
        "x_train, x_test = x_train / 255.0, x_test /255.0\n",
        "\n",
        "\n",
        "\n",
        "cnn_model = tf.keras.models.Sequential()\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation= 'relu', input_shape=(100,100,3)))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation= 'relu', input_shape=(100,100,3)))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation= 'relu', input_shape=(100,100,3)))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(64, activation= 'relu'))\n",
        "cnn_model.add(tf.keras.layers.Dropout(0.2))\n",
        "cnn_model.add(tf.keras.layers.Dense(10,activation = 'relu'))\n",
        "\n",
        "cnn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history = cnn_model.fit(x_train, y_train, epochs=100, batch_size = 64, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "0LNuGO3xYfJm"
      }
    }
  ]
}